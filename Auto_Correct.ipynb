{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " # **Auto-Correct system**\n",
        " \n",
        " We will implement an auto-correct system"
      ],
      "metadata": {
        "id": "5BFFHB1BSIxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "TZ3NRLKUzwLF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vx2iQFH_5ocp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process Data\n",
        "\n",
        "- Reading in a corpus (text file)\n",
        "- Changeing everything to lowercase\n",
        "- Returning a list of words."
      ],
      "metadata": {
        "id": "zbO9QDQ91AaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(file_name):\n",
        "       \n",
        "    #Open the file, read its contents into a string variable\n",
        "    with open(file_name, \"r\") as f:\n",
        "        text = f.read()\n",
        "    \n",
        "    # convert all letters to lower case\n",
        "    text = text.lower()\n",
        "    words = re.findall('\\w+',text)\n",
        "  \n",
        "    return words"
      ],
      "metadata": {
        "id": "JoofeUmJScc7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! git clone https://github.com/MarwanMohamed95/Auto-Correct\n",
        "\n",
        "word_l = process_data('/content/Auto-Correct/shakespeare.txt')\n",
        "vocab = set(word_l)  # this will be your new vocabulary\n",
        "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
        "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
      ],
      "metadata": {
        "id": "nB6H3eIAScZJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_count function\n",
        "\n",
        "- The dictionary's keys are words\n",
        "- The value for each word is the number of times that word appears in the corpus."
      ],
      "metadata": {
        "id": "aTS5imVj1XVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(word_l):\n",
        "    \n",
        "    word_count_dict = {}  \n",
        "    for word in word_l:\n",
        "        if word not in word_count_dict:\n",
        "            word_count_dict[word] = 1\n",
        "        else:\n",
        "            word_count_dict[word] += 1\n",
        "    return word_count_dict"
      ],
      "metadata": {
        "id": "jARKIN4gScXJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_dict = get_count(word_l)\n",
        "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
        "print(f\"The count for the word 'thee' is {word_count_dict.get('thee',0)}\")"
      ],
      "metadata": {
        "id": "YS2sofJoScTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18de3e4b-28af-4618-c712-7914bd1d9225"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 6116 key values pairs\n",
            "The count for the word 'thee' is 240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_probs function\n",
        "- This returns a dictionary where the keys are words, and the value for each word is its probability in the corpus of words."
      ],
      "metadata": {
        "id": "WtYLyw6Q1oLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probs(word_count_dict):\n",
        "    \n",
        "    probs = {}    \n",
        "    total = 0\n",
        "    for count in word_count_dict.values():\n",
        "        total += count\n",
        "    \n",
        "    probs = {word:p/total for word,p in word_count_dict.items()}\n",
        "    return probs"
      ],
      "metadata": {
        "id": "RchWjpk4ScRg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = get_probs(word_count_dict)\n",
        "print(f\"Length of probs is {len(probs)}\")\n",
        "print(f\"P('thee') is {probs['thee']:.4f}\")"
      ],
      "metadata": {
        "id": "QyyIbvhOScN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732ffc35-c404-4b1f-8621-d078562fc0c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of probs is 6116\n",
            "P('thee') is 0.0045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### String Manipulations\n",
        "we will write a few functions to manipulate strings so that we can edit the erroneous strings and return the right spellings of the words. we will implement four functions:\n",
        "\n",
        "- delete_letter: given a word, it returns all the possible strings that have one character removed.\n",
        "- switch_letter: given a word, it returns all the possible strings that have two adjacent letters switched.\n",
        "- replace_letter: given a word, it returns all the possible strings that have one character replaced by another different letter.\n",
        "- insert_letter: given a word, it returns all the possible strings that have an additional character inserted."
      ],
      "metadata": {
        "id": "CNGtt1WV2yiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_letter(word, verbose=False):\n",
        "    \n",
        "    split_l = [(word[:i],word[i:]) for i in range(len(word))]\n",
        "    delete_l = [L+R[1:] for L,R in split_l]\n",
        "\n",
        "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
        "\n",
        "    return  delete_l\n",
        "\n",
        "delete_word_l = delete_letter(word=\"cans\",verbose=True)"
      ],
      "metadata": {
        "id": "MGpspMCpScLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20700c3-050c-4fc5-c734-e8f155adc35a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word cans, \n",
            "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's')], \n",
            "delete_l = ['ans', 'cns', 'cas', 'can']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def switch_letter(word, verbose=False):\n",
        "    \n",
        "    split_l = [(word[:i],word[i:]) for i in range(len(word))]\n",
        "    switch_l = [a + b[1] + b[0] + b[2:] for a,b in split_l if len(b) >= 2]\n",
        "    \n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
        "    \n",
        "    return switch_l\n",
        "\n",
        "switch_word_l = switch_letter(word=\"eta\",verbose=True)"
      ],
      "metadata": {
        "id": "2cecMBxeScIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9caf7bb4-f250-406c-c228-5f5d83706e63"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = eta \n",
            "split_l = [('', 'eta'), ('e', 'ta'), ('et', 'a')] \n",
            "switch_l = ['tea', 'eat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_letter(word, verbose=False):\n",
        "    \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    \n",
        "    split_l = [(word[:i],word[i:]) for i in range(len(word))]\n",
        "    replace_l = [a + l + (b[1:] if len(b)> 1 else '') for a,b in split_l if b for l in letters]\n",
        "    replace_set=set(replace_l)    \n",
        "    replace_set.discard(word)\n",
        "    replace_l = sorted(list(replace_set))\n",
        "    \n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
        "    \n",
        "    return replace_l\n",
        "\n",
        "replace_l = replace_letter(word='can',verbose=True)"
      ],
      "metadata": {
        "id": "nkovbibJScBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74f06f0-1fb8-461d-eb2e-618003f01bda"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = can \n",
            "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
            "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_letter(word, verbose=False):\n",
        "    \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    split_l = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
        "    insert_l = [a + l + b for a,b in split_l for l in letters]\n",
        "    \n",
        "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
        "    \n",
        "    return insert_l\n",
        "\n",
        "insert_l = insert_letter('at', True)\n",
        "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
      ],
      "metadata": {
        "id": "I1r-BLe4Sb2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a2530a-7019-478f-d54f-3174db009825"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word at \n",
            "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
            "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
            "Number of strings output by insert_letter('at') is 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining the edits\n",
        "\n",
        "we will create two functions that, given a string, will return all the possible single and double edits on that string. These will be `edit_one_letter()` and `edit_two_letters()`."
      ],
      "metadata": {
        "id": "bpMx0u8y3lF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_one_letter(word, allow_switches = True):\n",
        "    \n",
        "    edit_one_set = set()    \n",
        "    if allow_switches == False:\n",
        "        edit_one_set = delete_letter(word) + replace_letter(word) + insert_letter(word) \n",
        "    else:\n",
        "        edit_one_set = delete_letter(word) + replace_letter(word) + insert_letter(word) + switch_letter(word)\n",
        "    \n",
        "    return set(edit_one_set)"
      ],
      "metadata": {
        "id": "lIoXXZzuTUip"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_word = \"at\"\n",
        "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
        "# turn this into a list to sort it, in order to view it\n",
        "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
        "\n",
        "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n",
        "print(f\"The type of the returned object should be a set {type(tmp_edit_one_set)}\")\n",
        "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaw4z8Lnxq-n",
        "outputId": "3dffdfac-e39b-489c-d6ac-35ab97ecac84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word at \n",
            "edit_one_l \n",
            "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
            "\n",
            "The type of the returned object should be a set <class 'set'>\n",
            "Number of outputs from edit_one_letter('at') is 129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the `edit_two_letters` function returns a set of words that are two edits away. Creating the additional edits based on the `edit_one_letter` function."
      ],
      "metadata": {
        "id": "pY9BCH9R31xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_two_letters(word, allow_switches = True):\n",
        "    \n",
        "    edit_two_set = set()    \n",
        "    edit_one_set = edit_one_letter(word,allow_switches = allow_switches)\n",
        "    for w in edit_one_set:\n",
        "        edit_one_set2 = edit_one_letter(w,allow_switches = allow_switches)\n",
        "        for s in edit_one_set2:\n",
        "            edit_two_set.add(s) \n",
        "    \n",
        "    return set(edit_two_set)"
      ],
      "metadata": {
        "id": "n8xGmKccTWGS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_edit_two_set = edit_two_letters(\"a\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
        "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
        "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
        "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
        "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
      ],
      "metadata": {
        "id": "o05J6-cHTWCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157e806f-852f-4e6e-fe14-1191a60c27ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of strings with edit distance of two: 2654\n",
            "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
            "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
            "The data type of the returned object should be a set <class 'set'>\n",
            "Number of strings that are 2 edit distances from 'at' is 7154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_corrections function \n",
        "- This function returns a list of zero to n possible suggestion tuples of the form (word, probability_of_word).\n",
        "\n",
        "we will generate suggestions for a supplied word using the edit functions we have developed. The 'suggestion algorithm' should follow this logic:\n",
        "\n",
        "- If the word is in the vocabulary, suggest the word.\n",
        "- Otherwise, if there are suggestions from edit_one_letter that are in the vocabulary, use those.\n",
        "- Otherwise, if there are suggestions from edit_two_letters that are in the vocabulary, use those.\n",
        "- Otherwise, suggest the input word.*"
      ],
      "metadata": {
        "id": "rTeQI5BDGq2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
        "    suggestions = []\n",
        "    n_best = []\n",
        "    \n",
        "    word_probs = {}\n",
        "    \n",
        "    if word in vocab:\n",
        "        word_probs[word] = probs[word]\n",
        "    \n",
        "    if len(word_probs) == 0:\n",
        "        one_edit_set = edit_one_letter(word, True)\n",
        "        for edited_word in one_edit_set:\n",
        "            if edited_word in vocab:\n",
        "                word_probs[edited_word] = probs[edited_word]\n",
        "    \n",
        "    if len(word_probs) == 0:\n",
        "        two_edits_set = edit_two_letters(word, True)\n",
        "        for edited_word in two_edits_set:\n",
        "            if edited_word in vocab:\n",
        "                word_probs[edited_word] = probs[edited_word]\n",
        "    \n",
        "    n_best = Counter(word_probs).most_common(n)\n",
        "    \n",
        "    for best_word, prob in n_best:\n",
        "        suggestions.append(best_word)\n",
        "    \n",
        "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
        "\n",
        "    return n_best"
      ],
      "metadata": {
        "id": "9y5wwNg4TWAW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_word = 'dys' \n",
        "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) # keep verbose=True\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")"
      ],
      "metadata": {
        "id": "n8rW3liuTV0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a320a86-179e-4dc6-b594-7c09f6ec09ad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entered word =  dys \n",
            "suggestions =  ['days', 'dye']\n",
            "word 0: days, probability 0.000410\n",
            "word 1: dye, probability 0.000019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7w8wFqaHpCv"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}